{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API_key from .env file\n",
    "from config_loader import ConfigLoader\n",
    "config = ConfigLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter 1 for Claude or 2 for GPT-3:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You selected Claude.\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import AIMessage\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "def select_model():\n",
    "    choice_map = {\n",
    "        \"1\": (\"Claude\", ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")),\n",
    "        \"2\": (\"GPT-3\", ChatOpenAI(model_name=\"gpt-3.5-turbo-1106\"))\n",
    "    }\n",
    "\n",
    "    while (choice := input(\"Enter 1 for Claude or 2 for GPT-3: \").strip()) not in choice_map:\n",
    "        print(\"Invalid choice. Please enter 1 or 2.\")\n",
    "\n",
    "    model_name, llm_instance = choice_map[choice]\n",
    "    print(f\"You selected {model_name}.\")\n",
    "    return llm_instance\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]    \n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "#Add New function; Tools\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "llm = select_model()\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "tool_node = ToolNode(tools=[tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "#This is new\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    interrupt_before=[\"tools\"],\n",
    "    # interrupt_after=[\"tools\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I'm learning LangGraph. Could you do some research on it for me?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Certainly! I'd be happy to research LangGraph for you. To get the most up-to-date and comprehensive information, I'll use the Tavily search engine to look this up. Let me do that for you now.\", 'type': 'text'}, {'id': 'toolu_01EKxe7qtC1ta3XokejDoryQ', 'input': {'query': 'LangGraph framework for building language model applications'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01EKxe7qtC1ta3XokejDoryQ)\n",
      " Call ID: toolu_01EKxe7qtC1ta3XokejDoryQ\n",
      "  Args:\n",
      "    query: LangGraph framework for building language model applications\n"
     ]
    }
   ],
   "source": [
    "user_input = \"I'm learning LangGraph. Could you do some research on it for me?\"\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tools',)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#현재 graph의 어느 위치에 있는지 확인\n",
    "snapshot = graph.get_state(config)\n",
    "#자이제 다음단계가 'chatbot'임을 알려줌\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=[{'text': \"Certainly! I'd be happy to research LangGraph for you. To get the most up-to-date and comprehensive information, I'll use the Tavily search engine to look this up. Let me do that for you now.\", 'type': 'text'}, {'id': 'toolu_01EKxe7qtC1ta3XokejDoryQ', 'input': {'query': 'LangGraph framework for building language model applications'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}] additional_kwargs={} response_metadata={'id': 'msg_018d82DBs7ZKGQoevvXqjm2E', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 414, 'output_tokens': 117}} id='run-878f1b67-ef5f-4ceb-aa3f-22ea8084495e-0' tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'LangGraph framework for building language model applications'}, 'id': 'toolu_01EKxe7qtC1ta3XokejDoryQ', 'type': 'tool_call'}] usage_metadata={'input_tokens': 414, 'output_tokens': 117, 'total_tokens': 531, 'input_token_details': {}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_search_results_json',\n",
       "  'args': {'query': 'LangGraph framework for building language model applications'},\n",
       "  'id': 'toolu_01EKxe7qtC1ta3XokejDoryQ',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_message = snapshot.values[\"messages\"][-1]\n",
    "print(existing_message)\n",
    "existing_message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#멈춰있는데 아래의 명령어를 듣고 재시작-1\n",
    "# exisiting_message를 보면 {'query': 'LangGraph for language models'} 로 LLM이 뽑은 쿼리가 합리적으로 느껴짐 그냥 두자\n",
    "# None이라는 명령어를 사람이 줘서 다음으로 갈수있게된것!\n",
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "\n",
    "#나중에는 Tool이 주는 메세지를 내가 생성하고나 덮어쓰는법을 배움\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"Certainly! I'd be happy to research LangGraph for you. To get the most up-to-date and comprehensive information, I'll use the Tavily search engine to look this up. Let me do that for you now.\", 'type': 'text'}, {'id': 'toolu_01EKxe7qtC1ta3XokejDoryQ', 'input': {'query': 'LangGraph framework for building language model applications'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search_results_json (toolu_01EKxe7qtC1ta3XokejDoryQ)\n",
      " Call ID: toolu_01EKxe7qtC1ta3XokejDoryQ\n",
      "  Args:\n",
      "    query: LangGraph framework for building language model applications\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search_results_json\n",
      "\n",
      "[{\"url\": \"https://www.datacamp.com/tutorial/langgraph-tutorial\", \"content\": \"LangGraph's structured framework ensures that each agent operates efficiently and effectively, making it suitable for tasks like automated customer support, data processing, and system monitoring. Multi-Agent systems. LangGraph excels in building applications where multiple agents collaborate to achieve a common goal.\"}, {\"url\": \"https://github.com/langchain-ai/langgraph\", \"content\": \"GitHub - langchain-ai/langgraph: Build resilient language agents as graphs. LangGraph Platform is a commercial solution for deploying agentic applications to production, built on the open-source LangGraph framework. Let's take a look at a simple example of an agent that can use a search tool. # Define the tools for the agent to use # This means that after `tools` is called, `agent` node is called next. workflow.add_edge(\\\"tools\\\", 'agent') Define entry point and graph edges.First, we need to set the entry point for graph execution - agent node. Normal edge: after the tools are invoked, the graph should always return to the agent to decide what to do next LangGraph adds the input message to the internal state, then passes the state to the entrypoint node, \\\"agent\\\".\"}]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Based on the search results, I can provide you with some information about LangGraph. Here's what I've learned:\n",
      "\n",
      "1. Purpose and Framework:\n",
      "   LangGraph is a framework designed for building language model applications. It provides a structured approach to creating complex, multi-agent systems that can collaborate on various tasks.\n",
      "\n",
      "2. Key Features:\n",
      "   - Structured Framework: LangGraph ensures that each agent in a system operates efficiently and effectively.\n",
      "   - Multi-Agent Systems: It excels in building applications where multiple agents work together to achieve a common goal.\n",
      "   - Graph-based Architecture: The framework uses a graph structure to define the flow and interactions between different components of an application.\n",
      "\n",
      "3. Use Cases:\n",
      "   LangGraph is suitable for various applications, including:\n",
      "   - Automated customer support\n",
      "   - Data processing\n",
      "   - System monitoring\n",
      "\n",
      "4. Components and Structure:\n",
      "   - Tools: The framework allows you to define tools that agents can use to perform tasks.\n",
      "   - Agents: These are the core components that make decisions and use tools.\n",
      "   - Workflow: You can define the flow of your application by adding edges between different nodes (like tools and agents).\n",
      "\n",
      "5. Example Structure:\n",
      "   Here's a simple example of how you might structure an agent in LangGraph:\n",
      "   - Define tools for the agent to use\n",
      "   - Set up the workflow by adding edges (e.g., connecting tools to the agent)\n",
      "   - Define the entry point for graph execution (typically the agent node)\n",
      "   - Set up normal edges to determine the flow (e.g., after tools are invoked, return to the agent for decision-making)\n",
      "\n",
      "6. State Management:\n",
      "   LangGraph manages an internal state, adding input messages to this state and passing it to the entry point node (usually the agent).\n",
      "\n",
      "7. Open-source and Commercial Versions:\n",
      "   - There's an open-source LangGraph framework available on GitHub.\n",
      "   - LangGraph Platform is a commercial solution for deploying agentic applications to production, built on top of the open-source framework.\n",
      "\n",
      "8. Integration:\n",
      "   It seems that LangGraph is related to or part of the LangChain ecosystem, as evidenced by the GitHub repository being under the \"langchain-ai\" organization.\n",
      "\n",
      "LangGraph appears to be a powerful tool for developers looking to create sophisticated, agent-based language model applications. It provides a structured way to manage complex interactions between multiple components, making it easier to build and maintain large-scale AI systems.\n",
      "\n",
      "Is there any specific aspect of LangGraph you'd like to know more about? I'd be happy to dive deeper into any particular area of interest.\n"
     ]
    }
   ],
   "source": [
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TheSecond",
   "language": "python",
   "name": "thesecond"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
